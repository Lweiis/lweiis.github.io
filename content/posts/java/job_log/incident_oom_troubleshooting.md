---
title: 生产事故-一次内存溢出问题排查
date: 2023-12-09
categories:
  - Java
  - Spring
tags:
  - Java
  - Troubleshooting
summary: 前人挖坑，后人填坑
series:
  - 开发记录
draft: true
---
# 问题过程：
**23-11 某周四下午：MQ 出现堆积，偶发性接口响应慢**  

**第一次排查**：  发现下午有 CPU 飙高，与 MQ 堆积时间点吻合  
同事说近日曾新增下午开始的定时任务，会发出大量 MQ  
我们很快达成一致，将锅甩给了定时任务  
向老板反馈：**定时任务时间需要挪到半夜闲时，并按此方案解决**

**错误从此时开始发酵**  
由于未复现问题和精准定位，我们草率给出结论，问题再次浮现

**安稳渡过一周又到周五下午**：偶发性接口响应慢，1/4服务器CPU飙高，出现内存溢出日志

**第二次排查**：  
1. 判断可能是由于某些**异常代码的执行或调用引起**的
	1. 查询问题前后时间范围内的 **API 网关记录**
	2. 从调用次数、响应时间上，**过滤出接口 A 和接口 B**
	3. 其中 A 为数据查询，外部调用次数非常频繁，且有少量明显超时
	4. B 为数据导出，响应时长正常可达分钟级
2. 我们无法从 OOM 日志得知到底是 A 还是 B 导致的（分布式架构下用跳板机 + 分散的日志带来一定困难）
	1. 尝试导出异常服务器上的**内存快照**，**失败**，因为16gb 的文件，从跳板机导出受云桌面和网络限制，几乎无法正常导出（必中断）
	2. 从公司内部云服务找到**线上 JVM 分析工具**，尝试使用 **Arthas 分析内存快照和GC**  
	   能发现 full GC 次数明显大于其他正常服务器  
	   但**内存快照分析失败**（文件体积和线上工具性能制约）
	4. 此时发现线上 JVM 分析工具能提供出内存快照下载
	5. 开始下载内存快照至云桌面，企图于本地使用 VisualVM 进行分析
	6. VisualVM 加载内存快照预估1.5 小时，时间也来到晚8点，俩人再次达成一致：先回家，到家再看
	7. Jconsole 终于加载完了，可能云桌面性能问题，堆内存分析和类列表加载仍然卡在 loading 无法分析（云桌面内存占用已经 98% 了，它尽力了）
3. VisualVM 分析失败后，我尝试将内存快照导入至 IDEA Profiler 中
	1. 加载成功（给 IDEA 点赞!!!），发现了海量的 C 类变量，明显与正常服务器的类变量不同
	2. 经过对 C 类的调用查询，定位到了接口 B、C、D 等，但按时间上看，接口 B 的嫌疑最大
	3. 于本地环境调用接口 B，成功引起本地服务 OOM 功能（我太傻了，我一开始就这么做不就好了）
	4. 时间为晚12点，暂时定论为接口 B 引起，问题延迟至周一解决
4. 